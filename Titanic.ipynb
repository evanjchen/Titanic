{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "revolutionary-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pca import pca\n",
    "\n",
    "from   sklearn.pipeline           import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing   import OneHotEncoder, QuantileTransformer, StandardScaler\n",
    "from sklearn.impute          import SimpleImputer\n",
    "from sklearn.compose         import ColumnTransformer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from   sklearn.experimental    import enable_iterative_imputer\n",
    "from   sklearn.impute          import *\n",
    "from sklearn.base import clone \n",
    "from   sklearn.metrics            import accuracy_score \n",
    "# Models\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.ensemble        import ExtraTreesClassifier, RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.ensemble        import RandomForestRegressor, StackingRegressor, BaggingRegressor\n",
    "from sklearn.linear_model    import LogisticRegression, RidgeClassifier\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "pacific-passion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.columns\n",
    "print(df.Survived.value_counts())\n",
    "df.info()\n",
    "\n",
    "# Relatively balanced class\n",
    "df.Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "cubic-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop PassengerId and Name because they are all unique\n",
    "unique = ['PassengerId', 'Name']\n",
    "\n",
    "y = df.Survived.values\n",
    "X = df.copy()\n",
    "X = df.drop(columns=unique)\n",
    "X = X.drop(columns = ['Survived']) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-consequence",
   "metadata": {},
   "source": [
    "# The SibSp and Parch seem to have very similar distributions, lets check if they are multi-collinear\n",
    "- We can attempt drop-column importance after fitting the initial model with just one of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "printable-advocacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"SIBSp Distribution\")\n",
    "df.SibSp.value_counts().plot(kind='bar')\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Parch Distribution\")\n",
    "df.Parch.value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "developing-diamond",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Pclass\")\n",
    "df['Pclass'].value_counts().plot(kind='bar')\n",
    "df.hist(column='Age', bins=20)\n",
    "df.hist(column='Fare', bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-puppy",
   "metadata": {},
   "source": [
    "# Mean Encoding (might be doing it wrong as it is encoding the entire set rather than basing on training set only)\n",
    "Looks like being female and 1st or 2nd class means high probability of survival. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "specified-seven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex\n",
      "female    0.742038\n",
      "male      0.188908\n",
      "Name: Survived, dtype: float64 Pclass\n",
      "1    0.629630\n",
      "2    0.472826\n",
      "3    0.242363\n",
      "Name: Survived, dtype: float64 Embarked\n",
      "C    0.553571\n",
      "Q    0.389610\n",
      "S    0.336957\n",
      "Name: Survived, dtype: float64 Sex     Pclass\n",
      "female  1         0.968085\n",
      "        2         0.921053\n",
      "        3         0.500000\n",
      "male    1         0.368852\n",
      "        2         0.157407\n",
      "        3         0.135447\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sex_mean_encoded = df.groupby(['Sex'])['Survived'].mean()\n",
    "class_mean_encoded = df.groupby(['Pclass'])['Survived'].mean()\n",
    "embark_mean_encoded = df.groupby(['Embarked'])['Survived'].mean()\n",
    "sex_class_mean_encoded = df.groupby(['Sex', 'Pclass'])['Survived'].mean()\n",
    "print(sex_mean_encoded, class_mean_encoded, embark_mean_encoded, sex_class_mean_encoded)\n",
    "\n",
    "X['sex_mean_enc'] = X['Sex'].map(sex_mean_encoded)\n",
    "X['class_enc'] = X['Pclass'].map(class_mean_encoded)\n",
    "X['embark_enc'] = X['Embarked'].map(embark_mean_encoded)\n",
    "\n",
    "# X = X.drop(columns=['Sex', 'Pclass', 'Embarked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-world",
   "metadata": {},
   "source": [
    "# Feature Engineering ('Cabin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "analyzed-highlight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin\n",
       "A    0.466667\n",
       "B    0.744681\n",
       "C    0.593220\n",
       "D    0.757576\n",
       "E    0.750000\n",
       "F    0.615385\n",
       "G    0.500000\n",
       "T    0.000000\n",
       "Z    0.299854\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cabin = X.Cabin.values\n",
    "cabin = [x[0] if isinstance(x, str) else 'Z' for x  in cabin ]\n",
    "counter = Counter(cabin)\n",
    "df['Cabin'] = cabin\n",
    "X['Cabin'] = cabin\n",
    "cabin_mean_encoded = df.groupby(['Cabin'])['Survived'].mean()\n",
    "\n",
    "X['cabin_enc'] = X['Cabin'].map(cabin_mean_encoded)\n",
    "cabin_mean_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-pathology",
   "metadata": {},
   "source": [
    "# Fill Numerical Nulls with mean and Categorical Nulls with Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "charming-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Age'].fillna((X['Age'].median(skipna=True)), inplace=True)\n",
    "X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)     # Note: Mode returns a series object so you need to specify index [0]\n",
    "\n",
    "# Due to Low cardinality, we can OHE Sex, and Embarked \n",
    "cat_cols = ['Pclass', 'Sex', 'Cabin', 'Embarked']  \n",
    "num_cols = ['Age', 'Fare', 'Parch', 'SibSp']    \n",
    "\n",
    "cat_prep = ColumnTransformer([('OHE', OneHotEncoder(handle_unknown='ignore'), cat_cols) ])\n",
    "num_prep = ColumnTransformer([('scl', StandardScaler(), num_cols) ])\n",
    "# num_prep = ColumnTransformer([ ('QT', QuantileTransformer(n_quantiles=20, output_distribution='normal'), num_cols)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "asian-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(models):\n",
    "    mean_scores = []\n",
    "    for model in models:\n",
    "        scores = []\n",
    "        pipe = Pipeline([('cat', cat_prep),\n",
    "                            ('model', model)])\n",
    "        for i in range(10):\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2)\n",
    "            pipe.fit(X_train, y_train)\n",
    "            y_pred = pipe.predict(X_val)\n",
    "            score = accuracy_score(y_val, y_pred)\n",
    "            scores.append(score)\n",
    "            \n",
    "        avg_score = np.mean(scores)\n",
    "        mean_scores.append(avg_score)\n",
    "        print(f\"MODEL: {model} SCORE:{avg_score}\")\n",
    "    return mean_scores\n",
    "\n",
    "\n",
    "def kfold_test(models, X, y):\n",
    "    mean_scores = []\n",
    "    for model in models:\n",
    "        scores = []\n",
    "        pipe = Pipeline([('cat', cat_prep),\n",
    "                            ('model', model)])\n",
    "\n",
    "        Kfold = StratifiedKFold(n_splits=5)\n",
    "        for train_index, test_index in Kfold.split(X,y):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_val = y[train_index], y[test_index]\n",
    "            pipe.fit(X_train, y_train)\n",
    "            y_pred = pipe.predict(X_val)\n",
    "            score = accuracy_score(y_val, y_pred)\n",
    "            scores.append(score)\n",
    "\n",
    "        avg_score = np.mean(scores)\n",
    "        mean_scores.append(avg_score)\n",
    "        print(f\"MODEL: {model} SCORE:{avg_score}\")\n",
    "    return mean_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "alert-finance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: RandomForestClassifier() SCORE:0.8036155922415418\n",
      "MODEL: SVC() SCORE:0.8024982738057875\n",
      "MODEL: LGBMClassifier() SCORE:0.8069926558282594\n",
      "MODEL: KNeighborsClassifier() SCORE:0.7845395769254913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8036155922415418,\n",
       " 0.8024982738057875,\n",
       " 0.8069926558282594,\n",
       " 0.7845395769254913]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [RandomForestClassifier(), SVC(), LGBMClassifier(), KNeighborsClassifier()]\n",
    "\n",
    "kfold_test(models, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-patio",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "monthly-serial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:52:45] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:52:45] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:52:46] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:52:46] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:52:47] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:52:48] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:52:48] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:52:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:52:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:52:50] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "MODEL: VotingClassifier(estimators=[('extra', ExtraTreesClassifier()),\n",
      "                             ('lgb', LGBMClassifier(n_estimators=200)),\n",
      "                             ('xg',\n",
      "                              XGBClassifier(base_score=None, booster=None,\n",
      "                                            colsample_bylevel=None,\n",
      "                                            colsample_bynode=None,\n",
      "                                            colsample_bytree=None, gamma=None,\n",
      "                                            gpu_id=None, importance_type='gain',\n",
      "                                            interaction_constraints=None,\n",
      "                                            learning_rate=None,\n",
      "                                            max_delta_step=None, max_depth=None,\n",
      "                                            min_child_weight=None, missing=nan,\n",
      "                                            monotone_constraints=None,\n",
      "                                            n_estimators=200, n_jobs=-1,\n",
      "                                            num_parallel_tree=None,\n",
      "                                            random_state=None, reg_alpha=None,\n",
      "                                            reg_lambda=None,\n",
      "                                            scale_pos_weight=None,\n",
      "                                            subsample=None, tree_method=None,\n",
      "                                            validate_parameters=None,\n",
      "                                            verbosity=None))],\n",
      "                 voting='soft') SCORE:0.8027932960893855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8027932960893855]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_tuned = rf.get_params()\n",
    "rf_tuned['n_estimators'] = 200\n",
    "rf = RandomForestClassifier(**rf_tuned)\n",
    "\n",
    "\n",
    "svc_tuned = SVC().get_params()\n",
    "svc_tuned['probability'] = True\n",
    "svc = SVC(**svc_tuned)\n",
    "\n",
    "\n",
    "\n",
    "lgbm_tuned = LGBMClassifier().get_params()\n",
    "lgbm_tuned['n_estimators'] = 200\n",
    "lgbm = LGBMClassifier(**lgbm_tuned)\n",
    "\n",
    "\n",
    "xg_tuned = XGBClassifier().get_params()\n",
    "xg_tuned['n_estimators'] = 200\n",
    "# xg_tuned['objective'] = 'logloss'\n",
    "xg_tuned['n_jobs'] = -1\n",
    "xg = XGBClassifier(**xg_tuned)\n",
    "\n",
    "\n",
    "extra = ExtraTreesClassifier()\n",
    "\n",
    "ensemble = VotingClassifier([('rf', rf),\n",
    "                           ('svc', svc),\n",
    "                           ('extra', extra),\n",
    "                            ('lgb', lgbm),\n",
    "                            ('xg', xg)],\n",
    "                            voting='soft')\n",
    "# kfold_test([ensemble], X, y)\n",
    "test_models([ensemble])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "positive-circular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:53:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:06] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:07] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:53:07] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "MODEL: VotingClassifier(estimators=[('extra', ExtraTreesClassifier()),\n",
      "                             ('lgb', LGBMClassifier(n_estimators=200)),\n",
      "                             ('xg',\n",
      "                              XGBClassifier(base_score=None, booster=None,\n",
      "                                            colsample_bylevel=None,\n",
      "                                            colsample_bynode=None,\n",
      "                                            colsample_bytree=None, gamma=None,\n",
      "                                            gpu_id=None, importance_type='gain',\n",
      "                                            interaction_constraints=None,\n",
      "                                            learning_rate=None,\n",
      "                                            max_delta_step=None, max_depth=None,\n",
      "                                            min_child_weight=None, missing=nan,\n",
      "                                            monotone_constraints=None,\n",
      "                                            n_estimators=200, n_jobs=-1,\n",
      "                                            num_parallel_tree=None,\n",
      "                                            random_state=None, reg_alpha=None,\n",
      "                                            reg_lambda=None,\n",
      "                                            scale_pos_weight=None,\n",
      "                                            subsample=None, tree_method=None,\n",
      "                                            validate_parameters=None,\n",
      "                                            verbosity=None))],\n",
      "                 voting='soft') SCORE:0.8092272926997678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8092272926997678]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold_test([ensemble], X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-clinton",
   "metadata": {},
   "source": [
    "# Fit on Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "designing-stage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:53:45] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv('test.csv')\n",
    "passenger_ids = X_test.PassengerId.values\n",
    "\n",
    "X_test['Age'].fillna((X_test['Age'].median(skipna=True)), inplace=True)\n",
    "X_test['Fare'].fillna((X_test['Fare'].median(skipna=True)), inplace=True)\n",
    "X_test['Embarked'].fillna(X_test['Embarked'].mode()[0], inplace=True)     # Note: Mode returns a series object so you need to specify index [0]\n",
    "\n",
    "\n",
    "# Cabin Features\n",
    "cabin = X_test.Cabin.values\n",
    "cabin = [x[0] if isinstance(x, str) else 'Z' for x  in cabin ]\n",
    "counter = Counter(cabin)\n",
    "X_test['Cabin'] = cabin\n",
    "\n",
    "\n",
    "# Mean-encoding\n",
    "X_test['sex_mean_enc'] = X_test['Sex'].map(sex_mean_encoded)\n",
    "X_test['class_enc'] = X_test['Pclass'].map(class_mean_encoded)\n",
    "X_test['cabin_enc'] = X_test['Cabin'].map(cabin_mean_encoded)\n",
    "X_test['embark_enc'] = X_test['Embarked'].map(embark_mean_encoded)\n",
    "\n",
    "# Drop uneeded columns\n",
    "X_test = X_test.drop(columns=unique)\n",
    "\n",
    "model = Pipeline([('cat', cat_prep),\n",
    "                            ('model', ensemble)])\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "rough-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "submission = pd.DataFrame()\n",
    "submission['PassengerId'] = passenger_ids\n",
    "submission['Survived'] = y_pred\n",
    "submission = submission.set_index(['PassengerId'])\n",
    "\n",
    "\n",
    "submission.to_csv('a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-patient",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-doctor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-detective",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-macintosh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "active-steal",
   "metadata": {},
   "source": [
    "# Feature Engineering (Titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sonic-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_master(x):\n",
    "    \"\"\"Check if 'master' is in passenger's name\"\"\"\n",
    "    if 'master' in x.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "wound-causing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "master\n",
       "0    0.374853\n",
       "1    0.575000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try dividing into families\n",
    "names = df.Name.values\n",
    "split_names = [name.split(',') for name in names]\n",
    "df['Last_name'] = df['Name'].str.split(',').str[0]\n",
    "df['Name_Title'] = df['Name'].str.split(',').str[1]\n",
    "\n",
    "# CHeck how mnany of the masters are first class\n",
    "df['master'] = df['Name_Title'].apply(is_master)\n",
    "df.groupby(['master'])['Survived'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "expressed-marking",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'master'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-04a1b7daee10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# It seems like master has nothing to do with class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'master'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Pclass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   6712\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6714\u001b[0;31m         return DataFrameGroupBy(\n\u001b[0m\u001b[1;32m   6715\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6716\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m    561\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'master'"
     ]
    }
   ],
   "source": [
    "# It seems like master has nothing to do with class\n",
    "df.groupby(['master', 'Pclass']).agg('size').unstack().plot(kind='bar', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-feature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-transaction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-skirt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alive-newspaper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-vessel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-pattern",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-keyboard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-study",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-profession",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-woman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "chinese-impact",
   "metadata": {},
   "source": [
    "# 4) Permutation Importance\n",
    "\n",
    "**Purpose:** Examine a feature's importance by randomly permuting the validation set's feature column's values <br>\n",
    "**Background/Explanation:**   When you train a model with a feature column, we are assuming that there is some value in the feature in its ability to predict target variable. How do you void the feature's ability to predict. You can simply randomly shuffle the feature column's values in the validation set. The feature's supposed ability to predict the target variable should be reduced to 0 with some random noise. <br>\n",
    "**Method:** \n",
    "1) Obtain benchmark model perfomance with all features. <br>\n",
    "2) Randomly permute the validation set's column's values and reassig.. <br>\n",
    "3) Subtract the metric form the benchmark. <br>\n",
    "\n",
    "**Additional Information:** There is no need to retrain a model so this method is faster than drop-column importance. <br>\n",
    "**WARNINGS:** Permutation Importance is only effective when we assume that the features are independent of each. It is not effective when there is multicollinearity between feature columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "solid-pollution",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'permute_col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5b5c3f8fbce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpermuted_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbench_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermute_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpermute_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Call permute_col function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mbench_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbench_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpermuted_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpermute_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'permute_col' is not defined"
     ]
    }
   ],
   "source": [
    "# Get average over 50 iterations \n",
    "n = 50\n",
    "bench_scores = []\n",
    "permuted_scores = np.zeros(shape=(n,len(X.columns)))\n",
    "for i in range(n):\n",
    "    bench_score, permute_score = permute_col(X, y, model=RandomForestClassifier())   # Call permute_col function\n",
    "    bench_scores.append(bench_score)\n",
    "    permuted_scores[i] = permute_score\n",
    "bench_avg = np.mean(bench_scores)\n",
    "permute_avgs = np.mean(dropped_scores, axis=0)\n",
    "permute_avgs = [(col, score) for col, score in zip(X.columns, permute_avgs)]\n",
    "plot_importances(bench_avg, permute_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run featimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected features contains the features selected by each method for k features\n",
    "k = 13\n",
    "all_scores, selected_features = compare_strat(k, PCA_features, spearman, dropped_avg, permute_avgs)\n",
    "labels = ['spearman', 'drop-col', 'permutation', 'PCA']\n",
    "plot_methods(k, all_scores, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X, y)\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X)\n",
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-coordinator",
   "metadata": {},
   "source": [
    "###  Examine how well each method performs in comparison to Shap using KendalTau's Rank Correlation Coefficient. For our case, **Spearman's R** Tau is the highest which means that its ranking of feature importance is most similar to the ground truth feature importance ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = ['ca', 'cp', 'chol', 'thal', 'oldpeak', 'thalach', 'sex', 'fbs', 'restecg']\n",
    "rank_truth = [i+1 for i in range(len(ground_truth))]\n",
    "# Compare how each method \n",
    "\n",
    "i = len(X.columns)\n",
    "feat_spear = get_best_features(spearman, i)\n",
    "feat_drop =  get_best_features(dropped_avg, i, reverse=False)\n",
    "feat_perm = get_best_features(permute_avgs, i, reverse=False)\n",
    "feat_PCA = PCA_features[:i]\n",
    "\n",
    "all_featimp = [feat_spear, feat_drop, feat_perm, feat_PCA]\n",
    "\n",
    "for method, features in zip(labels, all_featimp):\n",
    "    rank = [features.index(col)+1 for col in ground_truth]\n",
    "    tau, p_value = stats.kendalltau(rank, rank_truth)\n",
    "    print(f\"METHOD {method};  Kenall's Tau: {tau}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-orleans",
   "metadata": {},
   "source": [
    "# Automatic Feature Selection\n",
    "\n",
    "**Method**: \n",
    "1) Establish a benchmark validation error with all features included. <br>\n",
    "2) Remove the least important feature and calculate the average validation score with that feature removed. <br>\n",
    "3) Compare with the Benchmark to ensure the validation error is not dropping below the benchmark. <br>\n",
    "4) Recalculate Spearman's rank for the features that are leftover. <br>\n",
    "Iteratively go through 2, 3, and 4 and stop when the validation error is below the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_avg = selected_features_score(X, y, X.columns, model=RandomForestClassifier(),n=10)\n",
    "current_features, scores = remove_features(bench_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CURRENT FEATURES:\", current_features)\n",
    "plot_feature_removal(scores, bench_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-disaster",
   "metadata": {},
   "source": [
    "# Statistical Significance: Variance and Empirical p-values for Feature Importances\n",
    "Many times, the feature importance calculated could be the result of noise. How do we test this? When choosing a method for feature importance, we can iterate through it multiple times to\n",
    "To calculate the variances and standard deviation, we perform a MinMaxScaler to normalize the feature importances. We can see from the below graph that the 'fbs' column's feature importance is likely due to noise. If we run a hypothesis test with **a =. 0.05** we fail to reject the null hypothesis that the column's spearman's R is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = get_feature_variance(X)   # list of tuples (col, mean, variance)\n",
    "plot_feature_variance(normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-confidence",
   "metadata": {},
   "source": [
    "# Permuting the Y-column:\n",
    "**Purpose**: Determine if the feature importance is due to noise. <br>\n",
    "**Explanation** We would expect that a feature's importance to not be higher than the baseline when the target column is permuted randomly. We perform a null distribution hypothesis test to check if the baseline feature importance is not due to random noise. <br>\n",
    "**Method**:\n",
    "1) Get baseline feature importance score for columns. <br>\n",
    "2) For a set amount of iterations, randomly permute the target column and calculate the feature. <br>\n",
    "3) Count the number of times the column's feature imporrtance is greater than the base. <br>\n",
    "4) Divide each column's count by the total number of iterations. <br>\n",
    "5) If the percentage > 0.05, reject the null hypothesis that the feature's importance score is due to random noise. <br>\n",
    "\n",
    "\n",
    "### After randomly permuting the y-columns for and calculting the Spearman's R compared to the base, we can see that the 'fbs', 'restecg', and 'trestbps', and 'chol' columns had a 55.5%, 6.4%. 19.6%, and 19.6% chance of having their Spearman's R greater than their base. By conducting our hypothesis test, this suggests that these columns' feature importance scores were due to random noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_pval = permute_y(X, 1000)   # Permute 1000 times\n",
    "print(dic_pval)\n",
    "plot_pval(dic_pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-australia",
   "metadata": {},
   "source": [
    "###  **Issue:** Drop-column and Permutation Importance doesnot deal with multi-collinear features\n",
    "### **Reality:** In real-world problems, it is nearly impossible to determine if features are independent of each other. Generally, we should always assume that there is some multi-collinearity between features. How do we solve this issue? \n",
    "### **Solution:** Find the columns that are multi-collinear using a spearman's R matrix\n",
    "\n",
    "\n",
    "### **Explanation**: This heat map is a matrix that shows each features correlation with other columns. If there is a high multi-collinearity between 2 features, we should **drop or permute the columns together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X.corr(method='spearman')\n",
    "plt.subplots(figsize=(15,12))\n",
    "sns.heatmap(corr, annot=True, vmax=1, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-barbados",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-catalog",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
